---
title: "Data cleaning"
author: "Anne Christine Vig Jensen"
date: "`r Sys.Date()`"
output: html_document
---

In this markdown, we load in our experiment data, and combine the files into 1 dataset 

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE) #code + output is displayed 
knitr::opts_knit$set(root.dir = "~/Desktop/bachelor/onde_bachelor/experiment_folder/data") # set working directory 

# #read packages
pacman::p_load(readbulk, tidyverse)
```

```{r make dataset}
############################# Single File Workflow #############################

# #read packages
# pacman::p_load(readbulk, tidyverse)
# 
# #Read file
# file <- read.csv("trial_1_23-1_0.csv", header = FALSE )
# 
# #Add headers
# colnames(file) <- c("tap_sec", "group_member")
# 
# #Filter 1st and last row
# file_filtered <- file %>%
#    slice(-1, -n())
# 
# #Add column specifying condition
# file_filtered$condition <- "subgroup_loner"
# 
# #Add column specifying group number
# file_filtered$group_number <- 1
# 
# #Add column specifying trial
# file_filtered$trial <- 0
```


Combining the trial data - doesn't contain the ratings 
```{r}
# Define a function to process a single file
process_trial_file <- function(file_path) {
  # Check if the file is empty
  if (file.info(file_path)$size == 0) {
    message("Skipping empty file: ", file_path)
    return(NULL) # Skip processing this file
  }
  
  # Extract the filename (without directory and extension)
  file_name <- basename(file_path) %>% str_remove(".csv")
  
  # Extract information from the filename
  parts <- str_split(file_name, "_")[[1]]
  group_number <- as.numeric(parts[2])
  condition <- case_when(
    parts[3] == "123" ~ "123",
    parts[3] == "231" ~ "231",
    parts[3] == "312" ~ "312",
    parts[3] == "23-1" ~ "23-1",
    parts[3] == "1-23" ~ "1-23",
    parts[3] == "Simultaneous" ~ "simultaneous",
    TRUE ~ "unknown"  # Add a default case if new conditions are encountered
  )
  trial <- as.numeric(parts[4])
  
  # Read the file
  file <- read.csv(file_path, header = FALSE)
  
  # Add headers
  colnames(file) <- c("tap_sec", "participant")
  
  # Filter out the first and last rows
  file_filtered <- file %>%
    slice(-1, -n())
  
  # Add additional columns
  file_filtered_1 <- file_filtered %>%
    mutate(
      condition = condition,
      group_id = group_number,
      trial = trial
    )
  
  return(file_filtered_1)
}

# Directory containing your files
data_dir <- "~/Desktop/bachelor/onde_bachelor/experiment_folder/data"

# List all CSV files in the directory, excluding those with the "group" ratings
file_list <- list.files(data_dir, pattern = "*.csv", full.names = TRUE) %>%
  keep(~ !str_detect(basename(.), "group"))

# Process all files and combine them into a single data frame
all_data_no_ratings <- file_list %>%
  map_df(~ tryCatch(process_trial_file(.), error = function(e) {
    message("Error processing file: ", .)
    NULL # Skip file on error
  }))

# Ensure the folder "data_combined_nr" exists
output_dir <- "~/Desktop/bachelor/onde_bachelor/data_processing/"
if (!dir.exists(output_dir)) {
  dir.create(output_dir, recursive = TRUE)  # Create the folder if it doesn't exist
} 

# Save the combined data
write.csv(all_data_no_ratings, file = file.path(output_dir, "processed_data_no_ratings.csv"), row.names = FALSE)
```

Combining the group ratings 
```{r}
# Define a function to process files in the "group" category
process_group_file <- function(file_path) {
  # Read the file
  file <- read.csv(file_path, header = TRUE)  # Assuming these files have headers
  
  # Modify the "participant" column
  file <- file %>%
    mutate(participant = case_when(
      participant == "Blue" ~ 1,
      participant == "Black" ~ 2,
      participant == "Pink" ~ 3,
      TRUE ~ NA  # Handle unexpected values with NA
    )) %>% 
    mutate(condition = as.character(condition)) %>% #for now, making the condition column of type character
    mutate(condition = str_replace(condition, "Simultaneous", "simultaneous"))
  return(file)
}

# Directory containing your files
data_dir <- "~/Desktop/bachelor/onde_bachelor/experiment_folder/data"

# List all "group" files
group_file_list <- list.files(data_dir, pattern = "^group.*\\.csv$", full.names = TRUE)

# Process all "group" files
processed_group_files <- group_file_list %>%
  map_df(~ tryCatch(process_group_file(.), error = function(e) {
    message("Error processing group file: ", .)
    NULL  # Skip file on error
  }))
 
# Save the combined data
write.csv(processed_group_files, file = file.path(output_dir, "processed_data_ratings.csv"), row.names = FALSE)
```

```{r}
#temporarily setting wd to find combined files
setwd("~/Desktop/bachelor/onde_bachelor/data_processing/")

no_ratings_df <- read.csv("processed_data_no_ratings.csv")
ratings_df  <- read.csv("processed_data_ratings.csv") 
```

```{r combining + removing NA's}
#combining the no ratings df and the ratings df 
combined_data <- ratings_df %>% 
  left_join(no_ratings_df, by = join_by(group_id, condition, trial, participant))

#checking if na's present 
na_count <- sum(is.na(combined_data))
print(paste("Number of NA values in the dataset prior to removal:", na_count))

#dropping na's present  
combined_data <- combined_data %>% 
  drop_na()

#checking if na's present 
na_count <- sum(is.na(combined_data))
print(paste("Number of NA values in the dataset post removal:", na_count))
```

## Adding columns
```{r subgroup columns}
combined_data <- combined_data %>% 
  mutate(subgroup_present = ifelse(condition == "23-1"|condition == "1-23", 1,0)) %>% 
  mutate(is_a_subgroup_member = ifelse(subgroup_present == 1 & participant == "2"|
                                   subgroup_present == 1 & participant == "3", 
                                   1,0))
```

```{r ITIs}
# Group by trial and calculate IOI (inter-onset interval)
combined_data <- combined_data %>% 
  group_by(trial) %>% 
  mutate(iti = tap_sec - lag(tap_sec))  # Calculate IOI as the difference from the previous tap

combined_data <- combined_data %>% 
  group_by(group_id, condition, trial, participant) %>% 
  filter(iti > 0)

#checking if na's present 
na_count <- sum(is.na(combined_data))
print(paste("Number of NA values in the dataset", na_count))
```

```{r save datafile}
# Save the combined data
write.csv(combined_data, file = file.path(output_dir, "ratings_trials_combined.csv"), row.names = FALSE)
```


